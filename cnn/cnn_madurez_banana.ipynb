{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_DEpz0Nwu1c"
      },
      "source": [
        "Redes Neuronales Convolucionales\n",
        "=\n",
        "Clasificación de bananos según su estado de madurez, con el fin de realizar de manera más óptima su cosecha, selección y distribución."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definir la red"
      ],
      "metadata": {
        "id": "NFXZkNNN8OwZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntB3yDL1wu1d",
        "outputId": "e32a6bd7-02e9-4c48-fd68-288994ab91b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Red(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=44944, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=6, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Red(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Red, self).__init__()\n",
        "        # imagen de 3 canales (RGB), 6 canales de salida, dimensiones de 5x5\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # calcular total de parámetros por imagen: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 53 * 53, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 6) # 6 clases\n",
        "\n",
        "    # operaciones\n",
        "    def forward(self, entrada):\n",
        "        # Capa convolucional C1: recibe 1 imagen de 3 canales (RGB), produce 6 canales de salida, de dimensión 5x5 con activación ReLU\n",
        "        # y genera un tensor de tamaño (N, 6, 224, 224), donde N es el batch\n",
        "        c1 = F.relu(self.conv1(entrada))\n",
        "        # Capa de subsampling S2: max-pooling 2x2, sin parámetros, salida (N, 6, 14, 14), donde N es el batch\n",
        "        s2 = F.max_pool2d(c1, (2, 2))\n",
        "        # Capa convolucional C3: 6 canales de entrada, 16 de salida, dimensión de 5x5 con activación ReLU salidas a Tensor de (N, 16, 10, 10)\n",
        "        c3 = F.relu(self.conv2(s2))\n",
        "        # Capa de subsampling S4: max-pooling 2x2, sin parámetros, salida (N, 16, 53, 53), donde N es el batch\n",
        "        s4 = F.max_pool2d(c3, 2)\n",
        "        #print(\"Salidas y dimensiones:\",s4.shape)\n",
        "        # Operación Flatten: sin parámetros, salida (44944), donde N es el batch\n",
        "        s4 = torch.flatten(s4, 1)\n",
        "        # Capa totalmente conectada F5: entrada (44944), salida (120) con activación ReLU\n",
        "        f5 = F.relu(self.fc1(s4))\n",
        "        # Capa totalmente conectada F6: entrada (120), salida (84) con activación ReLU\n",
        "        f6 = F.relu(self.fc2(f5))\n",
        "        # Capa de salida (F7): entrada (84), salida (6) -> capa de clasificación\n",
        "        salida = self.fc3(f6)\n",
        "\n",
        "        return salida\n",
        "\n",
        "\n",
        "red = Red()\n",
        "print(red)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargar dataset\n",
        "En esta sección se carga todo el dataset de imágenes que se van a utilizar para entrenar, validar y probar el modelo."
      ],
      "metadata": {
        "id": "i4ucMeoYV5fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cargar dataset\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# descomprimir dataset\n",
        "ruta = \"../content/Banana_Ripeness\"\n",
        "rutas = [os.path.join(ruta, \"train\"), os.path.join(ruta, \"test\")]\n",
        "with zipfile.ZipFile(ruta+\".zip\", 'r') as zip_ref:\n",
        "        zip_ref.extractall(ruta)\n",
        "\n",
        "# transformar a tensor y normalizar dataset\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
        "\n",
        "batch_size = 32\n",
        "# entrenamiento (70%)\n",
        "training_data = datasets.ImageFolder(\n",
        "    root=rutas[0],\n",
        "    transform=transform\n",
        ")\n",
        "# test (15%)\n",
        "test_data = datasets.ImageFolder(\n",
        "    root=rutas[1],\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "# tamaño de test\n",
        "n_test = len(test_data)\n",
        "\n",
        "# dividir train en validación (15%)\n",
        "indices = list(range(len(training_data)))\n",
        "train_indices, val_indices = train_test_split(indices, test_size=n_test, random_state=42, shuffle=True)\n",
        "\n",
        "#dividir train y val\n",
        "train_data = Subset(training_data, train_indices)\n",
        "val_data = Subset(training_data, val_indices)\n",
        "\n",
        "# crear variables para datos de entrenamiento, validación y pruebas / DATALOADERS\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "print(\"Datos de entrenamiento:\",len(train_data))\n",
        "print(\"Datos de validación:\",len(val_data))\n",
        "print(\"Datos de prueba:\",len(test_data))\n",
        "print(\"Datos totales:\",len(training_data)+len(test_data)+len(val_data))\n",
        "# obtener clases\n",
        "clases=('freshripe','freshunripe','unripe','overripe','ripe','rotten')\n",
        "print(\"Clases:\",clases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypVIoh4b2OkE",
        "outputId": "95f4d4f1-e82c-4d6d-cd83-58031aca0341"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos de entrenamiento: 16332\n",
            "Datos de validación: 3501\n",
            "Datos de prueba: 3501\n",
            "Datos totales: 26835\n",
            "Clases: ('freshripe', 'freshunripe', 'unripe', 'overripe', 'ripe', 'rotten')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtener caractertisticas y etiquetas de las imágenes"
      ],
      "metadata": {
        "id": "OY1t9v-4Vh0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#obtener caracteristicas de imagenes y etiquetas\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Tamaño de lote, canales y dimensiones: {train_features.size()}\")\n",
        "print(f\"Número de etiquetas por cada lote: {train_labels.size()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eeIFmXk-3-g",
        "outputId": "e50f21b2-372e-4bfa-e475-52802a406d15"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño de lote, canales y dimensiones: torch.Size([32, 3, 224, 224])\n",
            "Número de etiquetas por cada lote: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definir función de pérdida y optimizador\n",
        "Mediante está función se optimiza el proceso de aprendizaje de la red a través de la Gradiente Descendente"
      ],
      "metadata": {
        "id": "VfHAnvWfWoh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterio = nn.CrossEntropyLoss()\n",
        "# momentum sirve para acelerar el proceso de encontrar el valor más cercano a cero\n",
        "optimizador = optim.SGD(red.parameters(), lr=0.001, momentum=0.9)\n",
        "print(optimizador)"
      ],
      "metadata": {
        "id": "qBPyCIhzWvmb",
        "outputId": "ea83c7f1-511a-430a-f746-da00c8fa6287",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurar uso de GPU\n",
        "Buscar dispositivo (GPU) disponible para acelerar entrenamiento"
      ],
      "metadata": {
        "id": "3TNLdnv9Ngmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# elección de arquitectura\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Usando:\",device)\n",
        "\n",
        "# Mover el modelo a GPU/CPU\n",
        "red.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2T0W9DwNmbF",
        "outputId": "60561338-17aa-457c-f59a-e3a03c2af58b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando: cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Red(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=44944, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento de la CNN\n",
        "Entrenamiento de la CNN mediante el uso del datos de entrenamiento en un número específico de épocas, dónde por cada una de estas se busca y actualiza el mejor modelo según la pérdida con los datos de validación."
      ],
      "metadata": {
        "id": "gf7e25JeWQ2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento de modelo\n",
        "mejor_modelo = None\n",
        "menor_perdida = float(\"inf\")\n",
        "m_epoca = 0\n",
        "train_perdida = []\n",
        "train_precision = []\n",
        "\n",
        "for epoca in range(10):  # número de épocas\n",
        "    red.train() # entrenamiento\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        entradas, etiquetas = data\n",
        "        # mover datos a GPU/CPU\n",
        "        entradas, etiquetas = entradas.to(device), etiquetas.to(device)\n",
        "        # gradiente de ceros\n",
        "        optimizador.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        salidas = red(entradas) # envío\n",
        "        perdida = criterio(salidas, etiquetas) # calculo diferencia o pérdida\n",
        "        perdida.backward() # Actualiza pesos\n",
        "        optimizador.step() # optimizo\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += perdida.item() # perdida acumulada\n",
        "    # pérdida promedio por época\n",
        "    perdida_promedio = running_loss / len(train_dataloader)\n",
        "    print(f\"[Epoca {epoca+1}, perdida promedio: {perdida_promedio:.3f}]\")\n",
        "\n",
        "    # guardar mejor modelo\n",
        "    if perdida_promedio < menor_perdida:\n",
        "        menor_perdida = perdida_promedio\n",
        "        m_epoca = epoca+1\n",
        "        mejor_modelo = red.state_dict()\n",
        "    # almacenar perdidas en train_perdida\n",
        "    train_perdida.append(perdida_promedio)\n",
        "\n",
        "    # validación\n",
        "    red.eval()\n",
        "    correcto, total, val_perdida = 0, 0, 0.0\n",
        "    with torch.no_grad():\n",
        "      for data in val_dataloader:\n",
        "        entradas, etiquetas = data\n",
        "        entradas, etiquetas = entradas.to(device), etiquetas.to(device)\n",
        "        salidas = red(entradas)\n",
        "        perdida_val = criterio(salidas, etiquetas)\n",
        "        val_perdida += perdida_val.item()\n",
        "        _, pred = torch.max(salidas, 1)\n",
        "        total += etiquetas.size(0)\n",
        "        correcto += (pred == etiquetas).sum().item()\n",
        "        #print(\"Precision:\", correcto/total*100)\n",
        "    # perdida y ganancia por época\n",
        "    val_perdida /= len(val_dataloader)\n",
        "    train_acc = 100 * correcto / total\n",
        "    train_precision.append(train_acc)\n",
        "    print(f\"Precision {train_acc:0.2f}% y perdida {val_perdida:0.2f} en entrenamiento\")\n",
        "\n",
        "print('='*60)\n",
        "print(f\"Modelo con menor perdida: {menor_perdida:0.5f}, Epoca {m_epoca}\")\n",
        "print('Entrenamiento finalizado')"
      ],
      "metadata": {
        "id": "LhWRm5--WWzY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db2a7c9c-ae76-44d7-d189-6ad9c07e4547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoca 1, perdida promedio: 1.590]\n",
            "Precision 44.42% y perdida 1.36 en entrenamiento\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Guardar mejor modelo"
      ],
      "metadata": {
        "id": "dPLWY8usZeAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ruta = './mejor_modelo_banana.pth'\n",
        "torch.save(mejor_modelo, ruta)"
      ],
      "metadata": {
        "id": "qXgUoj8UZhxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargar modelo entrenado"
      ],
      "metadata": {
        "id": "60AfTCtrac3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "red = Red()\n",
        "red.load_state_dict(torch.load(ruta, weights_only=True))\n",
        "print(\"Modelo cargado\")"
      ],
      "metadata": {
        "id": "B-mEMPk_afyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Probar modelo\n",
        "En esta sección se prueba el modelo con el fin de conocer la generalización de este ante los datos de test o prueba, y por ende calcular la precisión de este por cada clase.\n",
        "\n"
      ],
      "metadata": {
        "id": "15nK3-vwmbaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prueba de modelo por cada clase\n",
        "correct_pred = {classname: 0 for classname in clases}\n",
        "total_pred = {classname: 0 for classname in clases}\n",
        "\n",
        "# no se necesita la gradiente ya que se entrena una sola vez\n",
        "with torch.no_grad():\n",
        "    for data in test_dataloader:\n",
        "        imagenes, etiquetas = data\n",
        "        salidas = red(imagenes)\n",
        "        _, predicciones = torch.max(salidas, 1)\n",
        "        # collección de predicciones correctas por cada clase\n",
        "        for etiqueta, prediccion in zip(etiquetas, predicciones):\n",
        "            if etiqueta == prediccion:\n",
        "                correct_pred[clases[etiqueta]] += 1\n",
        "            total_pred[clases[etiqueta]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for n_clase, conteo_correctas in correct_pred.items():\n",
        "    accuracy = 100 * float(conteo_correctas) / total_pred[n_clase]\n",
        "    print(f'Accuracy por clase: {n_clase:5s} es {accuracy:.2f} %')"
      ],
      "metadata": {
        "id": "LvSi62zvmfrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Precisión total\n",
        "En esta sección se calcula la precisión total del modelo para clasificar todas las clases de madurez de banano."
      ],
      "metadata": {
        "id": "4aszH61ZoRC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calcular precisión en test\n",
        "correcto = 0\n",
        "total = 0\n",
        "# no se necesita la gradiente\n",
        "with torch.no_grad():\n",
        "    for data in test_dataloader:\n",
        "        entradas, etiquetas = data\n",
        "        # calculate outputs by running images through the network\n",
        "        salidas = red(entradas)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, prediccion = torch.max(salidas, 1)\n",
        "        total += etiquetas.size(0)\n",
        "        correcto += (prediccion == etiquetas).sum().item()\n",
        "print(f'Accuracy de la red con {len(test_data)} imagenes de test: {100 * correcto / total:.2f} %')"
      ],
      "metadata": {
        "id": "-SrcaDOvoUJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualización de resultados\n",
        "En esta sección se muestra la curvas tanto de pérdida como la curva de precisón en entrenamiento."
      ],
      "metadata": {
        "id": "1xRnwEMTfP2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Curva de pérdida\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_perdida, label='Entrenamiento')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.title('Curva de pérdida')\n",
        "plt.legend()\n",
        "\n",
        "# Curva de precisión\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(train_precision, label='Entrenamiento')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Precisión (%)')\n",
        "plt.title('Curva de precisión')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zTB36juKgh88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mostrar imágenes"
      ],
      "metadata": {
        "id": "9CORr2DpEA9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def mostrar_imagen(img, etiqueta_real, etiqueta_pred):\n",
        "    # Reordenar canales de [C,H,W] a [H,W,C]\n",
        "    img = img.permute(1, 2, 0)\n",
        "    # Desnormalizar (si usaste Normalize((0.5,...),(0.5,...)))\n",
        "    img = img * 0.5 + 0.5\n",
        "    plt.imshow(img.numpy())\n",
        "    plt.title(f\"Real: {clases[etiqueta_real]}\\nPred: {clases[etiqueta_pred]}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "def mostrar_imagenes(imagenes, etiquetas, predicciones, n=12):\n",
        "    filas = math.ceil(n / 5)   # hasta 5 columnas por fila\n",
        "    cols = min(n, 5)\n",
        "    plt.figure(figsize=(cols*3, filas*3))\n",
        "    for i in range(n):\n",
        "        plt.subplot(filas, cols, i+1)\n",
        "        mostrar_imagen(imagenes[i], etiquetas[i].item(), predicciones[i].item())\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Ejemplo: mostrar 20 imágenes\n",
        "dataiter = iter(test_dataloader)\n",
        "imagenes, etiquetas = next(dataiter)\n",
        "salidas = red(imagenes)\n",
        "_, predicciones = torch.max(salidas, 1)\n",
        "\n",
        "mostrar_imagenes(imagenes, etiquetas, predicciones, n=100)"
      ],
      "metadata": {
        "id": "kQSW7CvVEDL-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}