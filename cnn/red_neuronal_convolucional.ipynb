{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "noe5nn1swu1a"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_DEpz0Nwu1c"
      },
      "source": [
        "Neural Networks\n",
        "===============\n",
        "\n",
        "Neural networks can be constructed using the `torch.nn` package.\n",
        "\n",
        "Now that you had a glimpse of `autograd`, `nn` depends on `autograd` to\n",
        "define models and differentiate them. An `nn.Module` contains layers,\n",
        "and a method `forward(input)` that returns the `output`.\n",
        "\n",
        "For example, look at this network that classifies digit images:\n",
        "\n",
        "![convnet](https://pytorch.org/tutorials/_static/img/mnist.png)\n",
        "\n",
        "It is a simple feed-forward network. It takes the input, feeds it\n",
        "through several layers one after the other, and then finally gives the\n",
        "output.\n",
        "\n",
        "A typical training procedure for a neural network is as follows:\n",
        "\n",
        "-   Define the neural network that has some learnable parameters (or\n",
        "    weights)\n",
        "-   Iterate over a dataset of inputs\n",
        "-   Process input through the network\n",
        "-   Compute the loss (how far is the output from being correct)\n",
        "-   Propagate gradients back into the network's parameters\n",
        "-   Update the weights of the network, typically using a simple update\n",
        "    rule: `weight = weight - learning_rate * gradient`\n",
        "\n",
        "Definir la red\n",
        "------------------\n",
        "\n",
        "Let's define this network:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntB3yDL1wu1d",
        "outputId": "ee26f1d2-7d59-445f-e455-dab670eb92c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # 4*4 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    # operaciones\n",
        "    def forward(self, input):\n",
        "        # Convolution layer C1: 1 input image channel, 6 output channels,\n",
        "        # 5x5 square convolution, it uses RELU activation function, and\n",
        "        # outputs a Tensor with size (N, 6, 28, 28), where N is the size of the batch\n",
        "        c1 = F.relu(self.conv1(input))\n",
        "        # Subsampling layer S2: 2x2 grid, purely functional,\n",
        "        # this layer does not have any parameter, and outputs a (N, 6, 14, 14) Tensor\n",
        "        s2 = F.max_pool2d(c1, (2, 2))\n",
        "        # Convolution layer C3: 6 input channels, 16 output channels,\n",
        "        # 5x5 square convolution, it uses RELU activation function, and\n",
        "        # outputs a (N, 16, 10, 10) Tensor\n",
        "        c3 = F.relu(self.conv2(s2))\n",
        "        # Subsampling layer S4: 2x2 grid, purely functional,\n",
        "        # this layer does not have any parameter, and outputs a (N, 16, 5, 5) Tensor\n",
        "        s4 = F.max_pool2d(c3, 2)\n",
        "        # Flatten operation: purely functional, outputs a (N, 400) Tensor\n",
        "        s4 = torch.flatten(s4, 1)\n",
        "        # Fully connected layer F5: (N, 400) Tensor input,\n",
        "        # and outputs a (N, 120) Tensor, it uses RELU activation function\n",
        "        f5 = F.relu(self.fc1(s4))\n",
        "        # Fully connected layer F6: (N, 120) Tensor input,\n",
        "        # and outputs a (N, 84) Tensor, it uses RELU activation function\n",
        "        f6 = F.relu(self.fc2(f5))\n",
        "        # Gaussian layer OUTPUT: (N, 84) Tensor input, and\n",
        "        # outputs a (N, 10) Tensor\n",
        "        output = self.fc3(f6)\n",
        "        return output\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargar dataset"
      ],
      "metadata": {
        "id": "i4ucMeoYV5fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cargar dataset\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "batch_size = 64\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "# crear variables para datos de entrenamiento y pruebas\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "print(training_data)\n",
        "print(test_data)\n",
        "clases=training_data.classes\n",
        "print(clases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypVIoh4b2OkE",
        "outputId": "915cfc62-56c2-4feb-e9ff-846097ce42f9"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset FashionMNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=0.5, std=0.5)\n",
            "           )\n",
            "Dataset FashionMNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: data\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=0.5, std=0.5)\n",
            "           )\n",
            "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtener caractertisticas y etiquetas de las imágenes"
      ],
      "metadata": {
        "id": "OY1t9v-4Vh0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#obtener caracteristicas de imagenes y etiquetas\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Tamaño de batch, dimensiones y canales: {train_features.size()}\")\n",
        "print(f\"Número de etiquetas por cada batch: {train_labels.size()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eeIFmXk-3-g",
        "outputId": "a7322100-4c13-45a9-84ec-717d83750e6b"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño de batch, dimensiones y canales: torch.Size([64, 1, 28, 28])\n",
            "Número de etiquetas por cada batch: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definir función de perdida y optimizador"
      ],
      "metadata": {
        "id": "VfHAnvWfWoh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterio = nn.CrossEntropyLoss()\n",
        "# momentum sirve para acelerar el proceso de encontrar el valor más cercano a cero\n",
        "optimizador = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "qBPyCIhzWvmb"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurar uso de GPU"
      ],
      "metadata": {
        "id": "3TNLdnv9Ngmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# elección de arquitectura\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(\"Usando:\",device)\n",
        "\n",
        "# Mover el modelo a GPU/CPU\n",
        "net.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2T0W9DwNmbF",
        "outputId": "9f435203-6a3f-47b2-875e-e486c84b744b"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando: cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento del modelo de CNN"
      ],
      "metadata": {
        "id": "gf7e25JeWQ2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import M\n",
        "# Entrenamiento de modelo\n",
        "mejor_modelo = None\n",
        "mejor_perdida = float(\"inf\")\n",
        "m_epoca = 0\n",
        "\n",
        "for epoca in range(10):  # número de épocas\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        # get the entradas; data is a list of [entradas, etiquetas]\n",
        "        entradas, etiquetas = data\n",
        "        # mover datos a GPU/CPU\n",
        "        entradas, etiquetas = entradas.to(device), etiquetas.to(device)\n",
        "        # gradiente de ceros\n",
        "        optimizador.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        salidas = net(entradas) # envío\n",
        "        perdida = criterio(salidas, etiquetas) # calculo diferencia o pérdida\n",
        "        perdida.backward() # Actualiza pesos\n",
        "        optimizador.step() # optimizo\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += perdida.item() # perdida acumulada\n",
        "    perdida_promedio = running_loss / len(train_dataloader)\n",
        "    print(f\"Epoca {epoca+1}, perdida promedio: {perdida_promedio:.3f}\")\n",
        "\n",
        "    if perdida_promedio < mejor_perdida:    # print every 15000 mini-batches\n",
        "        m_perdida = perdida_promedio\n",
        "        m_epoca = epoca+1\n",
        "        mejor_modelo = net.state_dict()\n",
        "print('='*60)\n",
        "print(f\"Modelo con menor perdida: {mejor_perdida:0.3f}, Epoca {m_epoca}\")\n",
        "print('Entrenamiento finalizado')"
      ],
      "metadata": {
        "id": "LhWRm5--WWzY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "512d4ea0-b466-4705-9adb-c3fc801b61c1"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 1, perdida promedio: 1.537\n",
            "Epoca 2, perdida promedio: 0.735\n",
            "Epoca 3, perdida promedio: 0.643\n",
            "Epoca 4, perdida promedio: 0.587\n",
            "Epoca 5, perdida promedio: 0.534\n",
            "Epoca 6, perdida promedio: 0.492\n",
            "Epoca 7, perdida promedio: 0.459\n",
            "Epoca 8, perdida promedio: 0.432\n",
            "Epoca 9, perdida promedio: 0.410\n",
            "Epoca 10, perdida promedio: 0.391\n",
            "============================================================\n",
            "Modelo con menor perdida: inf, Epoca 10\n",
            "Entrenamiento finalizado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Guardar mejor modelo"
      ],
      "metadata": {
        "id": "dPLWY8usZeAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ruta = './best_model.pth'\n",
        "torch.save(mejor_modelo, ruta)"
      ],
      "metadata": {
        "id": "qXgUoj8UZhxy"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargar modelo entrenado"
      ],
      "metadata": {
        "id": "60AfTCtrac3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load(ruta, weights_only=True))"
      ],
      "metadata": {
        "id": "B-mEMPk_afyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a642df2-e522-43e2-b40f-3980a035ea54"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Probar modelo"
      ],
      "metadata": {
        "id": "15nK3-vwmbaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prueba de modelo por cada clase\n",
        "correct_pred = {classname: 0 for classname in clases}\n",
        "total_pred = {classname: 0 for classname in clases}\n",
        "\n",
        "# no se necesita la gradiente ya que se entrena una sola vez\n",
        "with torch.no_grad():\n",
        "    for data in test_dataloader:\n",
        "        imagenes, etiquetas = data\n",
        "        salidas = net(imagenes)\n",
        "        _, predicciones = torch.max(salidas, 1)\n",
        "        # collección de predicciones correctas por cada clase\n",
        "        for etiqueta, prediccion in zip(etiquetas, predicciones):\n",
        "            if etiqueta == prediccion:\n",
        "                correct_pred[clases[etiqueta]] += 1\n",
        "            total_pred[clases[etiqueta]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy por clase: {classname:5s} es {accuracy:.2f} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvSi62zvmfrx",
        "outputId": "a27b5a4f-6e81-4dac-b2f1-6ba3257b0f25"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy por clase: T-shirt/top es 86.60 %\n",
            "Accuracy por clase: Trouser es 94.80 %\n",
            "Accuracy por clase: Pullover es 76.30 %\n",
            "Accuracy por clase: Dress es 85.30 %\n",
            "Accuracy por clase: Coat  es 82.50 %\n",
            "Accuracy por clase: Sandal es 95.60 %\n",
            "Accuracy por clase: Shirt es 43.20 %\n",
            "Accuracy por clase: Sneaker es 96.20 %\n",
            "Accuracy por clase: Bag   es 96.60 %\n",
            "Accuracy por clase: Ankle boot es 92.30 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Precisión total"
      ],
      "metadata": {
        "id": "4aszH61ZoRC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correcto = 0\n",
        "total = 0\n",
        "# no se necesita la gradiente\n",
        "with torch.no_grad():\n",
        "    for data in test_dataloader:\n",
        "        imagenes, etiquetas = data\n",
        "        # calculate outputs by running images through the network\n",
        "        salidas = net(imagenes)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, prediccion = torch.max(salidas, 1)\n",
        "        total += etiquetas.size(0)\n",
        "        correcto += (prediccion == etiquetas).sum().item()\n",
        "\n",
        "print(f'Accuracy de la red con 10000 imagenes de test: {100 * correcto / total:.2f} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SrcaDOvoUJv",
        "outputId": "2c72169b-9d7e-4f93-dc92-7476ba65152f"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy de la red con 10000 imagenes de test: 84.94 %\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}