{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "noe5nn1swu1a"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_DEpz0Nwu1c"
      },
      "source": [
        "Neural Networks\n",
        "===============\n",
        "\n",
        "Neural networks can be constructed using the `torch.nn` package.\n",
        "\n",
        "Now that you had a glimpse of `autograd`, `nn` depends on `autograd` to\n",
        "define models and differentiate them. An `nn.Module` contains layers,\n",
        "and a method `forward(input)` that returns the `output`.\n",
        "\n",
        "For example, look at this network that classifies digit images:\n",
        "\n",
        "![convnet](https://pytorch.org/tutorials/_static/img/mnist.png)\n",
        "\n",
        "It is a simple feed-forward network. It takes the input, feeds it\n",
        "through several layers one after the other, and then finally gives the\n",
        "output.\n",
        "\n",
        "A typical training procedure for a neural network is as follows:\n",
        "\n",
        "-   Define the neural network that has some learnable parameters (or\n",
        "    weights)\n",
        "-   Iterate over a dataset of inputs\n",
        "-   Process input through the network\n",
        "-   Compute the loss (how far is the output from being correct)\n",
        "-   Propagate gradients back into the network's parameters\n",
        "-   Update the weights of the network, typically using a simple update\n",
        "    rule: `weight = weight - learning_rate * gradient`\n",
        "\n",
        "Define the network\n",
        "------------------\n",
        "\n",
        "Let's define this network:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntB3yDL1wu1d",
        "outputId": "f3d8d1f3-e0b4-4279-c101-6ebf0b7a17a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # 4*4 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    # operaciones\n",
        "    def forward(self, input):\n",
        "        # Convolution layer C1: 1 input image channel, 6 output channels,\n",
        "        # 5x5 square convolution, it uses RELU activation function, and\n",
        "        # outputs a Tensor with size (N, 6, 28, 28), where N is the size of the batch\n",
        "        c1 = F.relu(self.conv1(input))\n",
        "        # Subsampling layer S2: 2x2 grid, purely functional,\n",
        "        # this layer does not have any parameter, and outputs a (N, 6, 14, 14) Tensor\n",
        "        s2 = F.max_pool2d(c1, (2, 2))\n",
        "        # Convolution layer C3: 6 input channels, 16 output channels,\n",
        "        # 5x5 square convolution, it uses RELU activation function, and\n",
        "        # outputs a (N, 16, 10, 10) Tensor\n",
        "        c3 = F.relu(self.conv2(s2))\n",
        "        # Subsampling layer S4: 2x2 grid, purely functional,\n",
        "        # this layer does not have any parameter, and outputs a (N, 16, 5, 5) Tensor\n",
        "        s4 = F.max_pool2d(c3, 2)\n",
        "        # Flatten operation: purely functional, outputs a (N, 400) Tensor\n",
        "        s4 = torch.flatten(s4, 1)\n",
        "        # Fully connected layer F5: (N, 400) Tensor input,\n",
        "        # and outputs a (N, 120) Tensor, it uses RELU activation function\n",
        "        f5 = F.relu(self.fc1(s4))\n",
        "        # Fully connected layer F6: (N, 120) Tensor input,\n",
        "        # and outputs a (N, 84) Tensor, it uses RELU activation function\n",
        "        f6 = F.relu(self.fc2(f5))\n",
        "        # Gaussian layer OUTPUT: (N, 84) Tensor input, and\n",
        "        # outputs a (N, 10) Tensor\n",
        "        output = self.fc3(f6)\n",
        "        return output\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWNiY7T9wu1e"
      },
      "source": [
        "You just have to define the `forward` function, and the `backward`\n",
        "function (where gradients are computed) is automatically defined for you\n",
        "using `autograd`. You can use any of the Tensor operations in the\n",
        "`forward` function.\n",
        "\n",
        "The learnable parameters of a model are returned by `net.parameters()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG3ESNOgwu1e",
        "outputId": "882ff7b7-9a53-4f4c-b99c-8d42174bd3cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 1, 5, 5])\n"
          ]
        }
      ],
      "source": [
        "params = list(net.parameters())\n",
        "print(params[0].size())  # conv1's .weight"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#list(net.parameters()) # filtros con pesos aleatorios"
      ],
      "metadata": {
        "id": "1726reoTymZs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargar dataset"
      ],
      "metadata": {
        "id": "i4ucMeoYV5fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cargar dataset\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "batch_size = 32\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "# crear variables para entrenamiento para pruebas\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "print(training_data)\n",
        "print(test_data)\n",
        "clases=training_data.classes\n",
        "print(clases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypVIoh4b2OkE",
        "outputId": "753729aa-4e5f-4c4f-98f3-2b8a14c3165c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.4MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 505kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.68MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.68MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=0.5, std=0.5)\n",
            "           )\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: data\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=0.5, std=0.5)\n",
            "           )\n",
            "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtener caractertisticas y etiquetas de las imágenes"
      ],
      "metadata": {
        "id": "OY1t9v-4Vh0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#obtener caracteristicas de imagenes y etiquetas\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Tamaño de batch, dimensiones y canales: {train_features.size()}\")\n",
        "print(f\"Número de etiquetas por cada batch: {train_labels.size()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eeIFmXk-3-g",
        "outputId": "912875bf-a7dc-44d4-a435-dda97c0cb8a9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño de batch, dimensiones y canales: torch.Size([32, 1, 28, 28])\n",
            "Número de etiquetas por cada batch: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definir función de perdida y optimizador"
      ],
      "metadata": {
        "id": "VfHAnvWfWoh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterio = nn.CrossEntropyLoss()\n",
        "# momentum sirve para acelerar el proceso de encontrar el valor más cercano a cero\n",
        "optimizador = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "qBPyCIhzWvmb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurar uso de GPU"
      ],
      "metadata": {
        "id": "3TNLdnv9Ngmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"Usando:\",device)\n",
        "\n",
        "# Mover el modelo a GPU/CPU\n",
        "net.to(device)"
      ],
      "metadata": {
        "id": "b2T0W9DwNmbF",
        "outputId": "af649b5b-981a-46ff-896e-9806e10523f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando: cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento del modelo de CNN"
      ],
      "metadata": {
        "id": "gf7e25JeWQ2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento de modelo\n",
        "for epoca in range(5):  # número de épocas\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        # get the entradas; data is a list of [entradas, etiquetas]\n",
        "        entradas, etiquetas = data\n",
        "        # mover datos a GPU/CPU\n",
        "        entradas, etiquetas = entradas.to(device), etiquetas.to(device)\n",
        "        # gradiente de ceros\n",
        "        optimizador.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        salidas = net(entradas) # envío\n",
        "        perdida = criterio(salidas, etiquetas) # calculo diferencia o pérdida\n",
        "        perdida.backward() # Actualiza pesos\n",
        "        optimizador.step() # optimizo\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += perdida.item() # perdida acumulada\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'Época [{epoca + 1}, {i + 1:5d}] pérdida: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Entrenamiento finalizado')"
      ],
      "metadata": {
        "id": "LhWRm5--WWzY",
        "outputId": "ca4552f3-92a1-41de-8ac0-509366392c3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenamiento finalizado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Guardar modelo"
      ],
      "metadata": {
        "id": "dPLWY8usZeAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ruta = './mnist_cnn_net.pth'\n",
        "torch.save(net.state_dict(), ruta)"
      ],
      "metadata": {
        "id": "qXgUoj8UZhxy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Probar modelo"
      ],
      "metadata": {
        "id": "60AfTCtrac3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load(ruta, weights_only=True))"
      ],
      "metadata": {
        "id": "B-mEMPk_afyP",
        "outputId": "f30be875-609e-4354-88a4-75533ce0bf8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-QaXo1Btwu1f",
        "outputId": "59871eb8-1184-455b-ac78-ca10a4f2292f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 28, 28])\n",
            "tensor([[ -3.4849,  -0.5689,  15.1136,   6.6740,  -4.7466,  -5.9441, -12.1040,\n",
            "           2.7618,   3.3308,  -3.2477]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "#input = torch.randn(1, 1, 28, 28) # N lotes o batch, canales de entrada, dimensiones (w, h)\n",
        "input = train_features[0].unsqueeze(0) # enviar de uno a uno\n",
        "print(input.size())\n",
        "out = net(input)\n",
        "print(out)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}