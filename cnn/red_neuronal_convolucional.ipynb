{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "noe5nn1swu1a"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_DEpz0Nwu1c"
      },
      "source": [
        "Neural Networks\n",
        "===============\n",
        "\n",
        "Neural networks can be constructed using the `torch.nn` package.\n",
        "\n",
        "Now that you had a glimpse of `autograd`, `nn` depends on `autograd` to\n",
        "define models and differentiate them. An `nn.Module` contains layers,\n",
        "and a method `forward(input)` that returns the `output`.\n",
        "\n",
        "For example, look at this network that classifies digit images:\n",
        "\n",
        "![convnet](https://pytorch.org/tutorials/_static/img/mnist.png)\n",
        "\n",
        "It is a simple feed-forward network. It takes the input, feeds it\n",
        "through several layers one after the other, and then finally gives the\n",
        "output.\n",
        "\n",
        "A typical training procedure for a neural network is as follows:\n",
        "\n",
        "-   Define the neural network that has some learnable parameters (or\n",
        "    weights)\n",
        "-   Iterate over a dataset of inputs\n",
        "-   Process input through the network\n",
        "-   Compute the loss (how far is the output from being correct)\n",
        "-   Propagate gradients back into the network's parameters\n",
        "-   Update the weights of the network, typically using a simple update\n",
        "    rule: `weight = weight - learning_rate * gradient`\n",
        "\n",
        "Define the network\n",
        "------------------\n",
        "\n",
        "Let's define this network:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntB3yDL1wu1d",
        "outputId": "812e9e08-2e31-4d1e-ad40-a91abed23038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # 4*4 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    # operaciones\n",
        "    def forward(self, input):\n",
        "        # Convolution layer C1: 1 input image channel, 6 output channels,\n",
        "        # 5x5 square convolution, it uses RELU activation function, and\n",
        "        # outputs a Tensor with size (N, 6, 28, 28), where N is the size of the batch\n",
        "        c1 = F.relu(self.conv1(input))\n",
        "        # Subsampling layer S2: 2x2 grid, purely functional,\n",
        "        # this layer does not have any parameter, and outputs a (N, 6, 14, 14) Tensor\n",
        "        s2 = F.max_pool2d(c1, (2, 2))\n",
        "        # Convolution layer C3: 6 input channels, 16 output channels,\n",
        "        # 5x5 square convolution, it uses RELU activation function, and\n",
        "        # outputs a (N, 16, 10, 10) Tensor\n",
        "        c3 = F.relu(self.conv2(s2))\n",
        "        # Subsampling layer S4: 2x2 grid, purely functional,\n",
        "        # this layer does not have any parameter, and outputs a (N, 16, 5, 5) Tensor\n",
        "        s4 = F.max_pool2d(c3, 2)\n",
        "        # Flatten operation: purely functional, outputs a (N, 400) Tensor\n",
        "        s4 = torch.flatten(s4, 1)\n",
        "        # Fully connected layer F5: (N, 400) Tensor input,\n",
        "        # and outputs a (N, 120) Tensor, it uses RELU activation function\n",
        "        f5 = F.relu(self.fc1(s4))\n",
        "        # Fully connected layer F6: (N, 120) Tensor input,\n",
        "        # and outputs a (N, 84) Tensor, it uses RELU activation function\n",
        "        f6 = F.relu(self.fc2(f5))\n",
        "        # Gaussian layer OUTPUT: (N, 84) Tensor input, and\n",
        "        # outputs a (N, 10) Tensor\n",
        "        output = self.fc3(f6)\n",
        "        return output\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWNiY7T9wu1e"
      },
      "source": [
        "You just have to define the `forward` function, and the `backward`\n",
        "function (where gradients are computed) is automatically defined for you\n",
        "using `autograd`. You can use any of the Tensor operations in the\n",
        "`forward` function.\n",
        "\n",
        "The learnable parameters of a model are returned by `net.parameters()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG3ESNOgwu1e",
        "outputId": "05b42d24-43fd-4f27-afcf-7883010af4af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 1, 5, 5])\n"
          ]
        }
      ],
      "source": [
        "params = list(net.parameters())\n",
        "print(params[0].size())  # conv1's .weight"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#list(net.parameters()) # filtros con pesos aleatorios"
      ],
      "metadata": {
        "id": "1726reoTymZs"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargar dataset"
      ],
      "metadata": {
        "id": "i4ucMeoYV5fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cargar dataset\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "batch_size = 32\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "# crear variables para entrenamiento para pruebas\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "print(training_data)\n",
        "print(test_data)\n",
        "clases=training_data.classes\n",
        "print(clases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypVIoh4b2OkE",
        "outputId": "d59ec35a-d532-478d-b5c7-19fb20ff90e2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset FashionMNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=0.5, std=0.5)\n",
            "           )\n",
            "Dataset FashionMNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: data\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=0.5, std=0.5)\n",
            "           )\n",
            "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtener caractertisticas y etiquetas de las imágenes"
      ],
      "metadata": {
        "id": "OY1t9v-4Vh0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#obtener caracteristicas de imagenes y etiquetas\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Tamaño de batch, dimensiones y canales: {train_features.size()}\")\n",
        "print(f\"Número de etiquetas por cada batch: {train_labels.size()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eeIFmXk-3-g",
        "outputId": "f6004416-5a1e-4058-f7c5-466faccdb678"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño de batch, dimensiones y canales: torch.Size([32, 1, 28, 28])\n",
            "Número de etiquetas por cada batch: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definir función de perdida y optimizador"
      ],
      "metadata": {
        "id": "VfHAnvWfWoh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterio = nn.CrossEntropyLoss()\n",
        "# momentum sirve para acelerar el proceso de encontrar el valor más cercano a cero\n",
        "optimizador = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "qBPyCIhzWvmb"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurar uso de GPU"
      ],
      "metadata": {
        "id": "3TNLdnv9Ngmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(\"Usando:\",device)\n",
        "\n",
        "# Mover el modelo a GPU/CPU\n",
        "net.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2T0W9DwNmbF",
        "outputId": "d1b57847-af04-4d22-9baf-ca1055ef97e6"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando: cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento del modelo de CNN"
      ],
      "metadata": {
        "id": "gf7e25JeWQ2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento de modelo\n",
        "mini_batch = 5000\n",
        "for epoca in range(30):  # número de épocas\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        # get the entradas; data is a list of [entradas, etiquetas]\n",
        "        entradas, etiquetas = data\n",
        "        # mover datos a GPU/CPU\n",
        "        entradas, etiquetas = entradas.to(device), etiquetas.to(device)\n",
        "        # gradiente de ceros\n",
        "        optimizador.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        salidas = net(entradas) # envío\n",
        "        perdida = criterio(salidas, etiquetas) # calculo diferencia o pérdida\n",
        "        perdida.backward() # Actualiza pesos\n",
        "        optimizador.step() # optimizo\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += perdida.item() # perdida acumulada\n",
        "        if ((i+1) * batch_size) % mini_batch == 0:    # print every 5000 mini-batches\n",
        "            print(f'Época [{epoca + 1}, lote {i + 1:5d}] pérdida: {running_loss / (i+1):.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Entrenamiento finalizado')"
      ],
      "metadata": {
        "id": "LhWRm5--WWzY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf1aef1d-0621-4117-ddaf-1558d1c42f6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época [1,   625] pérdida: 0.262\n",
            "Época [1,  1250] pérdida: 0.133\n",
            "Época [1,  1875] pérdida: 0.087\n",
            "Época [2,   625] pérdida: 0.261\n",
            "Época [2,  1250] pérdida: 0.130\n",
            "Época [2,  1875] pérdida: 0.088\n",
            "Época [3,   625] pérdida: 0.263\n",
            "Época [3,  1250] pérdida: 0.132\n",
            "Época [3,  1875] pérdida: 0.087\n",
            "Época [4,   625] pérdida: 0.259\n",
            "Época [4,  1250] pérdida: 0.131\n",
            "Época [4,  1875] pérdida: 0.089\n",
            "Época [5,   625] pérdida: 0.266\n",
            "Época [5,  1250] pérdida: 0.131\n",
            "Época [5,  1875] pérdida: 0.087\n",
            "Época [6,   625] pérdida: 0.256\n",
            "Época [6,  1250] pérdida: 0.135\n",
            "Época [6,  1875] pérdida: 0.087\n",
            "Época [7,   625] pérdida: 0.261\n",
            "Época [7,  1250] pérdida: 0.131\n",
            "Época [7,  1875] pérdida: 0.088\n",
            "Época [8,   625] pérdida: 0.260\n",
            "Época [8,  1250] pérdida: 0.132\n",
            "Época [8,  1875] pérdida: 0.088\n",
            "Época [9,   625] pérdida: 0.260\n",
            "Época [9,  1250] pérdida: 0.134\n",
            "Época [9,  1875] pérdida: 0.087\n",
            "Época [10,   625] pérdida: 0.257\n",
            "Época [10,  1250] pérdida: 0.133\n",
            "Época [10,  1875] pérdida: 0.088\n",
            "Época [11,   625] pérdida: 0.261\n",
            "Época [11,  1250] pérdida: 0.132\n",
            "Época [11,  1875] pérdida: 0.087\n",
            "Época [12,   625] pérdida: 0.260\n",
            "Época [12,  1250] pérdida: 0.133\n",
            "Época [12,  1875] pérdida: 0.087\n",
            "Época [13,   625] pérdida: 0.270\n",
            "Época [13,  1250] pérdida: 0.128\n",
            "Época [13,  1875] pérdida: 0.087\n",
            "Época [14,   625] pérdida: 0.260\n",
            "Época [14,  1250] pérdida: 0.130\n",
            "Época [14,  1875] pérdida: 0.089\n",
            "Época [15,   625] pérdida: 0.259\n",
            "Época [15,  1250] pérdida: 0.132\n",
            "Época [15,  1875] pérdida: 0.088\n",
            "Época [16,   625] pérdida: 0.258\n",
            "Época [16,  1250] pérdida: 0.132\n",
            "Época [16,  1875] pérdida: 0.088\n",
            "Época [17,   625] pérdida: 0.262\n",
            "Época [17,  1250] pérdida: 0.132\n",
            "Época [17,  1875] pérdida: 0.087\n",
            "Época [18,   625] pérdida: 0.259\n",
            "Época [18,  1250] pérdida: 0.131\n",
            "Época [18,  1875] pérdida: 0.089\n",
            "Época [19,   625] pérdida: 0.263\n",
            "Época [19,  1250] pérdida: 0.133\n",
            "Época [19,  1875] pérdida: 0.086\n",
            "Época [20,   625] pérdida: 0.267\n",
            "Época [20,  1250] pérdida: 0.129\n",
            "Época [20,  1875] pérdida: 0.088\n",
            "Época [21,   625] pérdida: 0.262\n",
            "Época [21,  1250] pérdida: 0.132\n",
            "Época [21,  1875] pérdida: 0.087\n",
            "Época [22,   625] pérdida: 0.260\n",
            "Época [22,  1250] pérdida: 0.133\n",
            "Época [22,  1875] pérdida: 0.087\n",
            "Época [23,   625] pérdida: 0.259\n",
            "Época [23,  1250] pérdida: 0.133\n",
            "Época [23,  1875] pérdida: 0.088\n",
            "Época [24,   625] pérdida: 0.266\n",
            "Época [24,  1250] pérdida: 0.131\n",
            "Época [24,  1875] pérdida: 0.086\n",
            "Época [25,   625] pérdida: 0.264\n",
            "Época [25,  1250] pérdida: 0.130\n",
            "Época [25,  1875] pérdida: 0.088\n",
            "Época [26,   625] pérdida: 0.265\n",
            "Época [26,  1250] pérdida: 0.130\n",
            "Época [26,  1875] pérdida: 0.088\n",
            "Época [27,   625] pérdida: 0.255\n",
            "Época [27,  1250] pérdida: 0.136\n",
            "Época [27,  1875] pérdida: 0.087\n",
            "Época [28,   625] pérdida: 0.265\n",
            "Época [28,  1250] pérdida: 0.133\n",
            "Época [28,  1875] pérdida: 0.085\n",
            "Época [29,   625] pérdida: 0.261\n",
            "Época [29,  1250] pérdida: 0.131\n",
            "Época [29,  1875] pérdida: 0.088\n",
            "Época [30,   625] pérdida: 0.261\n",
            "Época [30,  1250] pérdida: 0.132\n",
            "Época [30,  1875] pérdida: 0.088\n",
            "Época [31,   625] pérdida: 0.263\n",
            "Época [31,  1250] pérdida: 0.132\n",
            "Época [31,  1875] pérdida: 0.087\n",
            "Época [32,   625] pérdida: 0.259\n",
            "Época [32,  1250] pérdida: 0.133\n",
            "Época [32,  1875] pérdida: 0.088\n",
            "Época [33,   625] pérdida: 0.257\n",
            "Época [33,  1250] pérdida: 0.132\n",
            "Época [33,  1875] pérdida: 0.089\n",
            "Época [34,   625] pérdida: 0.266\n",
            "Época [34,  1250] pérdida: 0.131\n",
            "Época [34,  1875] pérdida: 0.086\n",
            "Época [35,   625] pérdida: 0.261\n",
            "Época [35,  1250] pérdida: 0.130\n",
            "Época [35,  1875] pérdida: 0.089\n",
            "Época [36,   625] pérdida: 0.259\n",
            "Época [36,  1250] pérdida: 0.132\n",
            "Época [36,  1875] pérdida: 0.088\n",
            "Época [37,   625] pérdida: 0.263\n",
            "Época [37,  1250] pérdida: 0.132\n",
            "Época [37,  1875] pérdida: 0.087\n",
            "Época [38,   625] pérdida: 0.258\n",
            "Época [38,  1250] pérdida: 0.132\n",
            "Época [38,  1875] pérdida: 0.088\n",
            "Época [39,   625] pérdida: 0.263\n",
            "Época [39,  1250] pérdida: 0.132\n",
            "Época [39,  1875] pérdida: 0.087\n",
            "Época [40,   625] pérdida: 0.260\n",
            "Época [40,  1250] pérdida: 0.133\n",
            "Época [40,  1875] pérdida: 0.087\n",
            "Época [41,   625] pérdida: 0.263\n",
            "Época [41,  1250] pérdida: 0.131\n",
            "Época [41,  1875] pérdida: 0.087\n",
            "Época [42,   625] pérdida: 0.266\n",
            "Época [42,  1250] pérdida: 0.132\n",
            "Época [42,  1875] pérdida: 0.086\n",
            "Época [43,   625] pérdida: 0.258\n",
            "Época [43,  1250] pérdida: 0.132\n",
            "Época [43,  1875] pérdida: 0.088\n",
            "Época [44,   625] pérdida: 0.257\n",
            "Época [44,  1250] pérdida: 0.131\n",
            "Época [44,  1875] pérdida: 0.090\n",
            "Época [45,   625] pérdida: 0.257\n",
            "Época [45,  1250] pérdida: 0.135\n",
            "Época [45,  1875] pérdida: 0.087\n",
            "Época [46,   625] pérdida: 0.264\n",
            "Época [46,  1250] pérdida: 0.132\n",
            "Época [46,  1875] pérdida: 0.086\n",
            "Época [47,   625] pérdida: 0.262\n",
            "Época [47,  1250] pérdida: 0.132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Guardar modelo"
      ],
      "metadata": {
        "id": "dPLWY8usZeAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ruta = './mnist_cnn_net.pth'\n",
        "torch.save(net.state_dict(), ruta)"
      ],
      "metadata": {
        "id": "qXgUoj8UZhxy"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cargar modelo"
      ],
      "metadata": {
        "id": "60AfTCtrac3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load(ruta, weights_only=True))"
      ],
      "metadata": {
        "id": "B-mEMPk_afyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b886809-3471-4363-d8dc-e4595fe0d413"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prueba de modelo"
      ],
      "metadata": {
        "id": "15nK3-vwmbaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prueba de modelo por cada clase\n",
        "correct_pred = {classname: 0 for classname in clases}\n",
        "total_pred = {classname: 0 for classname in clases}\n",
        "\n",
        "# no se necesita la gradiente ya que se entrena una sola vez\n",
        "with torch.no_grad():\n",
        "    for data in test_dataloader:\n",
        "        imagenes, etiquetas = data\n",
        "        salidas = net(imagenes)\n",
        "        _, predicciones = torch.max(salidas, 1)\n",
        "        # collección de predicciones correctas por cada clase\n",
        "        for etiqueta, prediccion in zip(etiquetas, predicciones):\n",
        "            if etiqueta == prediccion:\n",
        "                correct_pred[clases[etiqueta]] += 1\n",
        "            total_pred[clases[etiqueta]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} es {accuracy:.2f} %')"
      ],
      "metadata": {
        "id": "LvSi62zvmfrx",
        "outputId": "2c212fd2-1820-4157-dbe5-dc837334d893",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class: T-shirt/top is 79.9 %\n",
            "Accuracy for class: Trouser is 97.0 %\n",
            "Accuracy for class: Pullover is 82.9 %\n",
            "Accuracy for class: Dress is 91.0 %\n",
            "Accuracy for class: Coat  is 80.0 %\n",
            "Accuracy for class: Sandal is 96.8 %\n",
            "Accuracy for class: Shirt is 71.3 %\n",
            "Accuracy for class: Sneaker is 96.6 %\n",
            "Accuracy for class: Bag   is 96.2 %\n",
            "Accuracy for class: Ankle boot is 94.6 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Precisión total"
      ],
      "metadata": {
        "id": "4aszH61ZoRC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correcto = 0\n",
        "total = 0\n",
        "# no se necesita la gradiente\n",
        "with torch.no_grad():\n",
        "    for data in test_dataloader:\n",
        "        imagenes, etiquetas = data\n",
        "        # calculate outputs by running images through the network\n",
        "        salidas = net(imagenes)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, prediccion = torch.max(salidas, 1)\n",
        "        total += etiquetas.size(0)\n",
        "        correcto += (prediccion == etiquetas).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correcto // total} %')"
      ],
      "metadata": {
        "id": "-SrcaDOvoUJv",
        "outputId": "29cf8893-f35d-45d5-d572-b8c888d54b17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 88 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "-QaXo1Btwu1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac067de-092a-459d-a93b-31da7bb3052c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 28, 28])\n",
            "tensor([[ 1.9865, -2.3575,  2.0949,  2.6959,  1.4992, -3.1907,  2.4035, -2.6306,\n",
            "         -1.9733, -2.2122]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "#input = torch.randn(1, 1, 28, 28) # N lotes o batch, canales de entrada, dimensiones (w, h)\n",
        "input = train_features[0].unsqueeze(0) # enviar de uno a uno\n",
        "print(input.size())\n",
        "out = net(input)\n",
        "print(out)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}